# SOME DESCRIPTIVE TITLE.
# Copyright (C) YEAR THE PACKAGE'S COPYRIGHT HOLDER
# This file is distributed under the same license as the PACKAGE package.
# FIRST AUTHOR <EMAIL@ADDRESS>, YEAR.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: PACKAGE VERSION\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2025-11-07 15:04+0100\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"Language: \n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Plural-Forms: nplurals=2; plural=(n > 1);\n"
#: templates/base.html:247
msgid "Accueil"
msgstr ""

#: templates/base.html:250
msgid "Actualités"
msgstr ""

#: templates/base.html:253
msgid "Chercheurs"
msgstr ""

#: templates/base.html:256
msgid "Partenaires"
msgstr ""

#: templates/base.html:259 templates/pages/contact.html:9
msgid "Nous contacter"
msgstr ""

#: templates/pages/accueil.html:9 templates/pages/actualites.html:11
#: templates/pages/partenaires.html:10
msgid "Bienvenue sur Labcom AIOLY"
msgstr ""

#: templates/pages/accueil.html:10 templates/pages/actualites.html:12
msgid ""
"Découvrez les dernières nouvelles, articles et informations sur nos projets "
"de recherche et innovations."
msgstr ""

#: templates/pages/actualites.html:7
#: templates/pages/polarisation_mueller.html:5
msgid "Actualités - Labcom AIOLY"
msgstr ""

#: templates/pages/actualites.html:16
msgid "Actualités :"
msgstr ""

#: templates/pages/actualites.html:21
msgid "Décembre 2025"
msgstr ""

#: templates/pages/actualites.html:22
msgid ""
"Publication de l'article : Simple methods for uncertainty estimation in "
"neural networks applied to spectral data processing"
msgstr ""

#: templates/pages/actualites.html:24
msgid ""
"\n"
"                    L’année s’est conclue par la publication de l’article « "
"Simple methods for uncertainty estimation in neural networks applied to "
"spectral data processing »\n"
"                    dans Chemometrics and Intelligent Laboratory Systems, "
"signé par Maxime Metz, Khadija Lamdibih, Jean-Michel Roger, David Esteve, "
"Ryad Bendoula et Florent Abdelghafour.\n"
"                    "
msgstr ""

#: templates/pages/actualites.html:33
msgid "Octobre 2025 | Tirana"
msgstr ""

#: templates/pages/actualites.html:34
msgid "Participation à la conférence SenseAIfood"
msgstr ""

#: templates/pages/actualites.html:36
msgid ""
"\n"
"                    Le LabCom AiLoY a participé à deux conférences majeures "
"consacrées à la spectroscopie et à la chimiométrie.\n"
"                    À ICNIRS 2025 (Rome), Maxime Metz a présenté un poster "
"sur la classification des plastiques,\n"
"                    Florent Abdelghafour a exposé des travaux sur "
"l’apprentissage profond appliqué aux données NIRS,\n"
"                    et Ivy Tumoine a proposé une étude sur la génération de "
"données synthétiques.\n"
"                    Aux 26ᵉ Rencontres Héliospir (Montpellier), l’équipe a "
"présenté plusieurs communications orales autour du Deep-Chemometrics,\n"
"                    comparant notamment différentes stratégies de "
"prétraitement et d’augmentation de données.\n"
"                    "
msgstr ""

#: templates/pages/actualites.html:49
msgid "Juin 2025 | Rome / Montpellier"
msgstr ""

#: templates/pages/actualites.html:50
msgid "Participation aux conférences ICNIRS et Héliospir"
msgstr ""

#: templates/pages/actualites.html:52
msgid ""
"\n"
"                    Le LabCom AiLoY a pris part à la conférence SenseAIfood "
"à Tirana, consacrée à l’intelligence artificielle et aux technologies "
"spectrales pour l’agroalimentaire.\n"
"                    Daniele Tanzilli a présenté ses travaux sur les "
"stratégies d’agrégation de prétraitements pour l’analyse spectrale.\n"
"                    Florent Abdelghafour a présenté une comparaison de "
"différentes architectures neuronales pour les données spectrales.\n"
"                    "
msgstr ""

#: templates/pages/actualites.html:62
msgid "04/11/2024 | Pertuis"
msgstr ""

#: templates/pages/actualites.html:63
msgid "Début de thèse d'Ivy Tumoine"
msgstr ""

#: templates/pages/actualites.html:65
msgid ""
"\n"
"                    Début de thèse de Ivy Tumoine sur l’auto-supervision "
"appliquée aux données hyper-spectrales.\n"
"                    Les premiers travaux se concentreront sur les "
"transformations à appliquer aux données spectrales.\n"
"                    "
msgstr ""

#: templates/pages/actualites.html:74
msgid "04/11/2024 | Montpellier"
msgstr ""

#: templates/pages/actualites.html:75
msgid "Participation à HELIOSPIR"
msgstr ""

#: templates/pages/actualites.html:77
msgid ""
"\n"
"                    Présentation de poster sur l’utilisation de l’active "
"learning pour calibrer des spectromètres entre eux.\n"
"                    Sessions d’échanges et workshops.\n"
"                    "
msgstr ""

#: templates/pages/actualites.html:88
msgid "Nos sujets de recherche :"
msgstr ""

#: templates/pages/actualites.html:92
msgid "Illustration Apprentissage auto-supervisé"
msgstr ""

#: templates/pages/actualites.html:94
msgid "Apprentissage auto-supervisé"
msgstr ""

#: templates/pages/actualites.html:96
msgid ""
"\n"
"                L'apprentissage auto-supervisé est une méthode "
"d'apprentissage qui ne requiert pas d'annotation manuelle.\n"
"                Le modèle apprend des représentations utiles en s'appuyant "
"sur des relations ou des structures internes présentes dans les données.\n"
"                "
msgstr ""

#: templates/pages/actualites.html:101 templates/pages/actualites.html:110
msgid "Lire plus"
msgstr ""

#: templates/pages/actualites.html:107
msgid "Illustration Polarisation de Mueller"
msgstr ""

#: templates/pages/actualites.html:109
msgid "Polarisation de Mueller"
msgstr ""

#: templates/pages/apprentissage_autosup.html:5
msgid "Apprentissage auto-supervisé - Labcom AIOLY"
msgstr ""

#: templates/pages/apprentissage_autosup.html:15
msgid "Illustration Article 1"
msgstr ""

#: templates/pages/apprentissage_autosup.html:18
msgid "L'apprentissage auto-supervisé"
msgstr ""

#: templates/pages/apprentissage_autosup.html:20
msgid ""
"\n"
"                L'apprentissage auto-supervisé est une méthode "
"d'apprentissage profond qui tire parti de larges bases de données non "
"annotées.\n"
"                Les modèles entraînés en auto-supervision présentent les "
"meilleures performances dans le traitement du langage, notamment avec les "
"chatbots, et d'excellentes performances en vision par ordinateur.\n"
"                "
msgstr ""

#: templates/pages/apprentissage_autosup.html:26
msgid "Apprentissage auto-supervisé pour le texte et l'image"
msgstr ""

#: templates/pages/apprentissage_autosup.html:28
msgid ""
"\n"
"                Pour entraîner un modèle à faire une tâche souhaitée, la "
"méthode classique d'apprentissage consiste à minimiser l'erreur entre la "
"prédiction du modèle et celle d'un annotateur humain.\n"
"                Obtenir une annotation est souvent long, pénible et "
"extrêmement onéreux — c'est la principale raison pour laquelle les modèles "
"auto-supervisés sont si intéressants.\n"
"                "
msgstr ""

#: templates/pages/apprentissage_autosup.html:34
msgid ""
"\n"
"                On peut voir un modèle neuronal profond comme la succession "
"d'un encodeur et d'un décodeur.\n"
"                L'encodeur permet d'obtenir des représentations des données "
"et le décodeur effectue la tâche souhaitée.\n"
"                La figure 1 illustre cela avec le modèle AlexNet : une "
"succession de convolutions permet d'obtenir une représentation de l'image, "
"puis quelques couches denses décodent cette information afin de déterminer "
"la classe correspondante.\n"
"                "
msgstr ""

#: templates/pages/apprentissage_autosup.html:43
msgid "Illustration de l’encodeur-décodeur"
msgstr ""

#: templates/pages/apprentissage_autosup.html:48
msgid ""
"\n"
"                Pour utiliser un modèle entraîné en auto-supervision afin de "
"réaliser une tâche donnée, on transfère l'encodeur du modèle et on y ajoute "
"un décodeur adapté.\n"
"                Transférer l'encodeur consiste à reprendre son architecture "
"et ses poids — c'est un simple copié-collé.\n"
"                L'ensemble encodeur + décodeur est ensuite entraîné à "
"accomplir la tâche souhaitée, comme illustré en figure 2.\n"
"                L'idée est qu'un encodeur entraîné en auto-supervision "
"produit de meilleures représentations des données qu'un encodeur initialisé "
"aléatoirement.\n"
"                "
msgstr ""

#: templates/pages/apprentissage_autosup.html:58
msgid "Illustration du transfert d’encodeur"
msgstr ""

#: templates/pages/apprentissage_autosup.html:63
msgid ""
"\n"
"                Afin d'apprendre à fournir de bonnes représentations, les "
"modèles entraînés en auto-supervision apprennent sur une <i>tâche prétexte</"
"i>.\n"
"                Cette tâche prétexte est fondée sur l'observation des "
"données et ne requiert aucune annotation manuelle.\n"
"                Il existe trois grandes familles de tâches prétextes :\n"
"                "
msgstr ""

#: templates/pages/apprentissage_autosup.html:72
msgid ""
"\n"
"                    <b>Les tâches de reconstruction.</b> À partir d'une "
"donnée dont on a masqué automatiquement une partie de l'information, le "
"modèle doit reconstruire la donnée complète.\n"
"                    Pour les images, cela peut consister à masquer "
"aléatoirement un groupe de pixels ; pour le texte, à cacher certains mots.\n"
"                    "
msgstr ""

#: templates/pages/apprentissage_autosup.html:78
msgid ""
"\n"
"                    <b>Les tâches contrastives.</b> Le modèle est entraîné à "
"obtenir des représentations proches pour des images similaires (paires "
"positives) et éloignées pour des images différentes (paires négatives).\n"
"                    Les paires positives sont obtenues en appliquant des "
"transformations (ou augmentations de données) à une même image.\n"
"                    "
msgstr ""

#: templates/pages/apprentissage_autosup.html:84
msgid ""
"\n"
"                    <b>Les tâches d'invariance.</b> Le modèle apprend à "
"obtenir des représentations proches pour des images similaires.\n"
"                    Une solution triviale serait de considérer toutes les "
"images comme identiques — un phénomène appelé <i>effondrement</i>.\n"
"                    Pour éviter cela, des contraintes de régularisation sont "
"appliquées durant l'entraînement.\n"
"                    "
msgstr ""

#: templates/pages/apprentissage_autosup.html:92
msgid "L'apprentissage auto-supervisé appliqué aux données spectrales"
msgstr ""

#: templates/pages/apprentissage_autosup.html:94
msgid ""
"\n"
"                Si l'apprentissage auto-supervisé est très populaire pour "
"les images et le texte, il est encore quasi inexistant pour les données "
"spectrales.\n"
"                C'est pourquoi PellencST et l'équipe COMIC ont lancé une "
"thèse intitulée « Apprentissage auto-supervisé appliqué aux données "
"spectrales pour le tri des déchets ».\n"
"                Cette thèse, réalisée par Ivy Tumoine, est co-dirigée par "
"Ryad Bendoula et Jean-Michel Roger, et co-encadrée par Maxime Metz et "
"Florent Abdelghafour.\n"
"                "
msgstr ""

#: templates/pages/apprentissage_autosup.html:102
msgid ""
"\n"
"                L'adaptation de ces approches auto-supervisées nécessite de "
"lever trois verrous méthodologiques majeurs :\n"
"                "
msgstr ""

#: templates/pages/apprentissage_autosup.html:109
msgid ""
"\n"
"                    <b>Augmentation de données spectrales.</b> Les approches "
"auto-supervisées cherchent à rendre les modèles invariants à certaines "
"perturbations via des augmentations de données.\n"
"                    Cependant, peu de recherches concernent les "
"augmentations adaptées aux spectres.\n"
"                    Comme ces transformations influencent directement les "
"connaissances apprises, elles doivent être conçues en tenant compte de la "
"nature des données spectrales : composition, dépendances lointaines, "
"conditions de mesure, etc.\n"
"                    "
msgstr ""

#: templates/pages/apprentissage_autosup.html:116
msgid ""
"\n"
"                    <b>Réseaux neuronaux adaptés aux données spectrales.</b> "
"Ces approches nécessiteront sans doute des architectures mieux adaptées aux "
"spectres.\n"
"                    Si de nombreux réseaux existent pour les images et les "
"vidéos, peu sont optimisés pour les données spectrales.\n"
"                    Les ResNet, par exemple, ne prennent pas toujours en "
"compte les corrélations lointaines entre longueurs d’onde.\n"
"                    De nouvelles architectures comme les Transformers (SWIN, "
"ViT, etc.) devront être explorées.\n"
"                    "
msgstr ""

#: templates/pages/apprentissage_autosup.html:124
msgid ""
"\n"
"                    <b>Stratégies d'auto-supervision adaptées aux données "
"spectrales.</b> Les stratégies utilisées dans d'autres domaines ne tiennent "
"pas compte de la structure spectrale.\n"
"                    Par exemple, le masquage spatial classique n'est pas "
"adapté car certaines signatures spectrales ne dépendent que d'une gamme de "
"longueurs d'onde.\n"
"                    L'objectif sera donc de concevoir de nouvelles "
"stratégies d'auto-supervision adaptées, par exemple en masquant une partie "
"des structures latentes.\n"
"                    "
msgstr ""

#: templates/pages/apprentissage_autosup.html:135
#: templates/pages/polarisation_mueller.html:98
msgid "Retour"
msgstr ""

#: templates/pages/chercheurs.html:7
msgid "Chercheurs - Labcom AIOLY"
msgstr ""

#: templates/pages/chercheurs.html:11
msgid "Nos Chercheuses et Chercheurs"
msgstr ""

#: templates/pages/chercheurs.html:12
msgid ""
"Découvrez les membres de notre équipe de recherche de part et d'autres du "
"Labcom."
msgstr ""

#: templates/pages/chercheurs.html:17
msgid "INRAE"
msgstr ""

#: templates/pages/chercheurs.html:27 templates/pages/chercheurs.html:46
msgid "Voir plus"
msgstr ""

#: templates/pages/chercheurs.html:36 templates/pages/contact.html:18
msgid "Pellenc ST"
msgstr ""

#: templates/pages/chercheurs_page.html:5
msgid "Chercheur - Labcom AIOLY"
msgstr ""

#: templates/pages/chercheurs_page.html:27
msgid "Domaine de recherche :"
msgstr ""

#: templates/pages/chercheurs_page.html:30
msgid "Publications :"
msgstr ""

#: templates/pages/chercheurs_page.html:35
msgid "Aucune publication disponible."
msgstr ""

#: templates/pages/chercheurs_page.html:41
msgid "Brevets récents :"
msgstr ""

#: templates/pages/chercheurs_page.html:46
msgid "Aucun brevet disponible."
msgstr ""

#: templates/pages/chercheurs_page.html:51
msgid "Biographie :"
msgstr ""

#: templates/pages/chercheurs_page.html:55
msgid "Aucune biographie disponible."
msgstr ""

#: templates/pages/chercheurs_page.html:60
msgid "Google Scholar :"
msgstr ""

#: templates/pages/chercheurs_page.html:67
msgid "LinkedIn :"
msgstr ""

#: templates/pages/chercheurs_page.html:76
msgid "Retour à la liste des chercheurs"
msgstr ""

#: templates/pages/contact.html:5
msgid "Contacts - Labcom AIOLY"
msgstr ""

#: templates/pages/contact.html:10
msgid "Pour tout contact ou demande d'informations veuillez contacter :"
msgstr ""

#: templates/pages/contact.html:13
msgid "Equipe COMIC, Inrae"
msgstr ""

#: templates/pages/contact.html:24
msgid "Animation illustrative"
msgstr ""

#: templates/pages/partenaires.html:5
msgid "Partenaires - Labcom AIOLY"
msgstr ""

#: templates/pages/partenaires.html:11
msgid ""
"Ce laboratoire commun est un partenariat entre les deux institutions de "
"renommée mondiale que sont :"
msgstr ""

#: templates/pages/partenaires.html:16
msgid "Logo INRAE"
msgstr ""

#: templates/pages/partenaires.html:27
msgid "Logo Pellenc ST"
msgstr ""

#: templates/pages/polarisation_mueller.html:14
msgid "Illustration polarisation Mueller"
msgstr ""

#: templates/pages/polarisation_mueller.html:17
msgid "L'imagerie par polarisation de Mueller"
msgstr ""

#: templates/pages/polarisation_mueller.html:18
msgid ""
"L'imagerie polarimétrique est un type d'imagerie utilisant la polarisation "
"de la lumière comme source d'information. Elle se base sur les propriétés de "
"réflexion et transmission des différents objets étudiés, qui modifient un "
"état de polarisation initial."
msgstr ""

#: templates/pages/polarisation_mueller.html:19
msgid ""
"Ce type d'imagerie permet ainsi d'obtenir des informations sur la structure "
"microscopique des objets. Pour les polymères, cette information est "
"particulièrement intéressante, car un même monomère peut donner des "
"structures polymères différentes."
msgstr ""

#: templates/pages/polarisation_mueller.html:20
msgid ""
"Elle permet également de séparer les réflexions multiples en profondeur d'un "
"objet des réflexions en surface. On peut utiliser l'imagerie polarimétrique "
"comme un 'filtre' afin de ne conserver que l'information souhaitée."
msgstr ""

#: templates/pages/polarisation_mueller.html:22
msgid "La polarisation :"
msgstr ""

#: templates/pages/polarisation_mueller.html:23
msgid ""
"Une onde lumineuse est une onde électromagnétique constituée d'un champ "
"électrique (E) et d'un champ magnétique (B) oscillant perpendiculairement "
"l'un à l'autre et à la direction de propagation."
msgstr ""

#: templates/pages/polarisation_mueller.html:27
msgid "Illustration onde électromagnétique"
msgstr ""

#: templates/pages/polarisation_mueller.html:31
msgid ""
"Dans la lumière naturelle, comme celle du Soleil, ces oscillations se "
"produisent dans toutes les directions perpendiculaires à la direction de "
"propagation : on parle de lumière 'non polarisée'. La lumière est dite "
"'polarisée' lorsqu'elle ne vibre que dans certaines directions spécifiques."
msgstr ""

#: templates/pages/polarisation_mueller.html:32
msgid ""
"La polarisation peut être linéaire (vibrations dans une seule direction), "
"circulaire (oscillations décrivant un cercle autour de l'axe de "
"propagation), ou elliptique (oscillations suivant une ellipse)."
msgstr ""

#: templates/pages/polarisation_mueller.html:34
msgid "Formalisme de Stokes :"
msgstr ""

#: templates/pages/polarisation_mueller.html:35
msgid ""
"Pour caractériser entièrement la polarisation de la lumière, on utilise "
"généralement le formalisme de Stokes, représenté sous forme d'un vecteur :"
msgstr ""

#: templates/pages/polarisation_mueller.html:39
msgid "On peut ainsi reconnaître : "
msgstr ""

#: templates/pages/polarisation_mueller.html:41
msgid "I comme l'intensité totale"
msgstr ""

#: templates/pages/polarisation_mueller.html:42
msgid "Q comme le contraste entre la polarisation 0° et 90°"
msgstr ""

#: templates/pages/polarisation_mueller.html:43
msgid "U comme le contraste entre la polarisation +45° et -45°"
msgstr ""

#: templates/pages/polarisation_mueller.html:44
msgid ""
"V comme le contraste entre les polarisations circulaires droite et gauche"
msgstr ""

#: templates/pages/polarisation_mueller.html:47
msgid "Représentation dans la sphère de Poincaré :"
msgstr ""

#: templates/pages/polarisation_mueller.html:48
msgid ""
"Ce vecteur est souvent ramené en trois dimensions en normalisant par I. La "
"sphère de Poincaré permet de représenter graphiquement les états de "
"polarisation."
msgstr ""

#: templates/pages/polarisation_mueller.html:51
msgid "Sphère de Poincaré"
msgstr ""

#: templates/pages/polarisation_mueller.html:55
msgid "Matrice de Mueller :"
msgstr ""

#: templates/pages/polarisation_mueller.html:56
msgid ""
"La matrice de Mueller M_objet définit la transformation d'un vecteur S_init "
"en un vecteur S_sortie après interaction avec un objet ou élément optique."
msgstr ""

#: templates/pages/polarisation_mueller.html:59
msgid "Principe de mesure :"
msgstr ""

#: templates/pages/polarisation_mueller.html:60
msgid ""
"La polarisation incidente est générée par un PSG (Polarization State "
"Generator), l'objet est étudié, et l'état de sortie est analysé par un PSA "
"(Polarization State Analyser)."
msgstr ""

#: templates/pages/polarisation_mueller.html:62
msgid "Montage en réflexion"
msgstr ""

#: templates/pages/polarisation_mueller.html:65
msgid "PSG et PSA :"
msgstr ""

#: templates/pages/polarisation_mueller.html:66
msgid ""
"Le PSG permet d'obtenir toutes les polarisations souhaitées. Le PSA, "
"constitué des mêmes éléments optiques mais dans l'ordre inverse, analyse "
"l'état de sortie."
msgstr ""

#: templates/pages/polarisation_mueller.html:70
msgid "Retardance du Cristal Liquide 1"
msgstr ""

#: templates/pages/polarisation_mueller.html:74
msgid "Retardance du Cristal Liquide 2"
msgstr ""

#: templates/pages/polarisation_mueller.html:78
msgid "Retardance du Cristal Liquide 1'"
msgstr ""

#: templates/pages/polarisation_mueller.html:82
msgid "Retardance du Cristal Liquide 2'"
msgstr ""

#: templates/pages/polarisation_mueller.html:86
msgid "Manipulations :"
msgstr ""

#: templates/pages/polarisation_mueller.html:87
msgid "Les manipulations sont actuellement en cours."
msgstr ""

#: templates/pages/polarisation_mueller.html:88
msgid "Résultats :"
msgstr ""

#: templates/pages/polarisation_mueller.html:89
msgid "À venir."
msgstr ""

#: templates/pages/polarisation_mueller.html:91
msgid "Sources :"
msgstr ""

#: templates/pages/polarisation_mueller.html:92
msgid ""
"[1] Sami Ben Hatit. Polarimétrie de Mueller résolue en angle. Physics "
"[physics]. École Polytechnique X,2009."
msgstr ""
