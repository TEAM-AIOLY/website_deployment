

<!DOCTYPE html>
<html lang="fr">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Apprentissage auto-supervis√© - Labcom AIOLY</title>
    <style>
        /* Styles g√©n√©raux */
        body {
            font-family: Arial, sans-serif;
            margin: 0;
            padding: 0;
            box-sizing: border-box;
            background-color: #fafafa;
        }

        .container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 0 20px;
        }

        header {
            background-color: #002F5C;
            padding: 0px 10px;
            display: flex;
            justify-content: space-between;
            align-items: center;
        }

        nav ul {
            list-style: none;
            margin: 0;
            padding: 0;
            display: flex;
            align-items: center;
        }

        nav ul li {
            margin-right: 20px;
        }

        nav ul li a {
            color: white;
            text-decoration: none;
            font-size: 16px;
            display: inline-block;
            padding: 20px 20px; /* padding identique pour tous */
            border-radius: 10px; /* arrondi doux */
            transition: background-color 0.3s ease, color 0.3s ease;
        }

        nav ul li a.active {
            background-color: white;
            color: #002F5C;
        }

        .logo img {
            height: 60px;
            margin-right: 80px;
        }

        .logo_inrae img {
            height: 40px;
            margin-right: 80px;
        }

        .main-content {
            padding: 20px 0;
        }
        .article {
            display: flex; /* Flexbox pour aligner l'image et le texte */
            border: 1px solid #ccc; /* Bordure autour de l'article */
            border-radius: 5px;
            padding: 15px;
            margin-bottom: 20px; /* Espace entre les articles */
            align-items: center; /* Aligner les items au d√©but */
            background-color: white;
        }

        .article img {
            max-width: 150px; /* Largeur maximale de l'image */
            width: auto; /* Largeur automatique pour garder le ratio */
            height: auto; /* Hauteur automatique pour garder le ratio */
            object-fit: cover; /* Couvrir tout l'espace disponible tout en gardant le ratio */
            margin-right: 15px; /* Espace entre l'image et le texte */
            border-radius: 5px; /* Coins arrondis pour l'image */
        }
        .logos-container {
            display: flex;
            align-items: center;
            justify-content: center; /* ou space-between si tu veux les √©carter */
            gap: 40px; /* espace entre les logos */
        }
        footer {
            background-color: #002F5C;
            color: white;
            text-align: center;
            padding: 10px 0;
            position: relative;
            bottom: 0;
            width: 100%;
        }
        .actualites_evenements {
            margin-top: 2rem;
        }

        .actualites-liste {
            max-height: 400px; /* hauteur fixe de la zone */
            overflow-y: auto;  /* active la barre de d√©filement verticale */
            padding-right: 10px;
            scroll-behavior: smooth;
        }

        .actualite {
            background-color: #f8f8f8;
            border-radius: 10px;
            padding: 15px;
            margin-bottom: 15px;
            box-shadow: 0 2px 6px rgba(0,0,0,0.1);
            transition: transform 0.2s ease;
        }

        .actualite:hover {
            transform: scale(1.0);
        }
        .actualite h1 {
            color: grey;
            font-size: small;
        }
        .actualite h2 {
            font-size: medium;
        }
        .chercheurs-groupes {
			display: flex; /* Utilise Flexbox pour afficher les colonnes */
			justify-content: space-between; /* S√©pare les colonnes */
			gap: 20px; /* Espace entre les colonnes */
		}

		.groupe {
			flex: 1; /* Chaque colonne prend la m√™me largeur */
			padding: 15px;
			border: 1px solid #ccc; /* Optionnel : ajoute une bordure autour des colonnes */
			border-radius: 5px; /* Coins arrondis */
		}

		.groupe h2 {
			text-align: center; /* Centre le titre du groupe */
		}

		.profile {
			display: flex;
			margin-bottom: 20px;
		}

		.profile img {
			max-width: 100px; /* Ajustez la taille des images */
			margin-right: 15px;
			border-radius: 5px;
		}

        /* S√©lecteur de langue */
        .lang-switcher {
            display: flex;
            align-items: center;
            margin-right: 20px;
        }

        .lang-switcher select {
            background-color: #002F5C;
            color: white;
            border: none;
            font-size: 14px;
            padding: 6px 8px;
            border-radius: 5px;
            cursor: pointer;
        }

        .lang-switcher select:hover {
            background-color: #004080;
        }


        @media (max-width: 768px) {
			.chercheurs-groupes {
				flex-direction: column; /* Passe √† une colonne sur les petits √©crans */
			}
		}
        @media (max-width: 768px) {
            header {
                flex-direction: column;
                align-items: center;
            }

            nav ul {
                flex-direction: column;
            }

            nav ul li {
                margin: 10px 0;
            }
        }
        .article .social-media {
			margin-top: 10px; /* Ajoute un peu d'espace entre le texte et les ic√¥nes */
			display: flex;
		}

		.article .social-media a {
			margin-right: 10px; /* Espace entre les ic√¥nes */
		}

		.article .social-icon {
			width: 24px;
			height: 24px;
			transition: transform 0.3s ease;
		}

		.article .social-icon:hover {
			transform: scale(3); /* Agrandit l'ic√¥ne au survol */
		}
        table {
            border-collapse: collapse;
            width: 90%;
        }
        th, td {
            border: 1px solid black;
            padding: 10px;
            text-align: center;
			font-size: 1.1em;
        }
		th{
		background-color: #f4f4f4;
		}
    </style>
    <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>
<body>



<header>
    <nav>
        <ul>
            <li>
                <a href="/fr/" class="">Accueil</a>
            </li>
            <li>
                <a href="/fr/actualites/" class="">Actualit√©s</a>
            </li>
            <li>
                <a href="/fr/chercheurs/" class="">Chercheurs</a>
            </li>
            <li>
                <a href="/fr/partenaires/" class="">Partenaires</a>
            </li>
            <li>
                <a href="/fr/contact/" class="">Nous contacter</a>
            </li>
        </ul>
    </nav>

    <div class="logos-container">
        <div class="logo">
            <img src="/website_deployment/static/Images/Image1.png" alt="Logo Labcom">
        </div>
        <div class="logo_inrae">
            <a href="https://www.inrae.fr" target="_blank" rel="noopener noreferrer">
                <img src="/website_deployment/static/Images/Logo_INRAE_Transparent.png" alt="Logo INRAE">
            </a>
        </div>
        <div class="logo">
            <a href="https://www.pellencst.com" target="_blank" rel="noopener noreferrer">
                <img src="/website_deployment/static/Images/Logo_pellenc.png" alt="Logo Pellenc">
            </a>
        </div>
    </div>

    <!-- üåç S√©lecteur de langue simple -->
    <div class="lang-switcher">
        <form method="get" id="lang-form">
            <select name="lang" onchange="changeLang(this)">
                <option value="fr" selected>Fran√ßais</option>
                <option value="en" >English</option>
            </select>
        </form>
    </div>

    <script>
        function changeLang(select) {
            const lang = select.value;
            // Redirection vers la page correspondante dans la langue choisie
            const pathParts = window.location.pathname.split('/').filter(p => p);
            // Remplace la premi√®re partie (la langue) par la nouvelle langue
            if(pathParts.length > 0 && ['fr','en'].includes(pathParts[0])) {
                pathParts[0] = lang;
            } else {
                pathParts.unshift(lang);
            }
            window.location.href = '/' + pathParts.join('/') + '/';
        }
    </script>
</header>

<div class="container main-content">
    

<!-- Contenu principal -->
<div class="container main-content">

    <!-- Article 1 -->
    <div class="article" style="display: flex; align-items: flex-start;">
        <img src="/website_deployment/static/Images/selfsupdino.png"
             alt="Illustration Article 1"
             style="vertical-align: top; margin-right: 20px;">
        <div>
            <h2>L'apprentissage auto-supervis√©</h2>
            <p>
                
                L'apprentissage auto-supervis√© est une m√©thode d'apprentissage profond qui tire parti de larges bases de donn√©es non annot√©es.
                Les mod√®les entra√Æn√©s en auto-supervision pr√©sentent les meilleures performances dans le traitement du langage, notamment avec les chatbots, et d'excellentes performances en vision par ordinateur.
                
            </p>

            <h3>Apprentissage auto-supervis√© pour le texte et l'image</h3>
            <p>
                
                Pour entra√Æner un mod√®le √† faire une t√¢che souhait√©e, la m√©thode classique d'apprentissage consiste √† minimiser l'erreur entre la pr√©diction du mod√®le et celle d'un annotateur humain.
                Obtenir une annotation est souvent long, p√©nible et extr√™mement on√©reux ‚Äî c'est la principale raison pour laquelle les mod√®les auto-supervis√©s sont si int√©ressants.
                
            </p>
            <p>
                
                On peut voir un mod√®le neuronal profond comme la succession d'un encodeur et d'un d√©codeur.
                L'encodeur permet d'obtenir des repr√©sentations des donn√©es et le d√©codeur effectue la t√¢che souhait√©e.
                La figure 1 illustre cela avec le mod√®le AlexNet : une succession de convolutions permet d'obtenir une repr√©sentation de l'image, puis quelques couches denses d√©codent cette information afin de d√©terminer la classe correspondante.
                
            </p>

            <div class="figure">
                <img src="/website_deployment/static/Images/enc_dec.png"
                     alt="Illustration de l‚Äôencodeur-d√©codeur"
                     style="max-width: 50%; margin-right: 30%; padding-top: 10px;">
            </div>

            <p>
                
                Pour utiliser un mod√®le entra√Æn√© en auto-supervision afin de r√©aliser une t√¢che donn√©e, on transf√®re l'encodeur du mod√®le et on y ajoute un d√©codeur adapt√©.
                Transf√©rer l'encodeur consiste √† reprendre son architecture et ses poids ‚Äî c'est un simple copi√©-coll√©.
                L'ensemble encodeur + d√©codeur est ensuite entra√Æn√© √† accomplir la t√¢che souhait√©e, comme illustr√© en figure 2.
                L'id√©e est qu'un encodeur entra√Æn√© en auto-supervision produit de meilleures repr√©sentations des donn√©es qu'un encodeur initialis√© al√©atoirement.
                
            </p>

            <div class="figure">
                <img src="/website_deployment/static/Images/auto_sup_entr.png"
                     alt="Illustration du transfert d‚Äôencodeur"
                     style="max-width: 55%; margin-right: 30%; padding-top: 10px;">
            </div>

            <p>
                
                Afin d'apprendre √† fournir de bonnes repr√©sentations, les mod√®les entra√Æn√©s en auto-supervision apprennent sur une <i>t√¢che pr√©texte</i>.
                Cette t√¢che pr√©texte est fond√©e sur l'observation des donn√©es et ne requiert aucune annotation manuelle.
                Il existe trois grandes familles de t√¢ches pr√©textes :
                
            </p>

            <ul>
                <li>
                    
                    <b>Les t√¢ches de reconstruction.</b> √Ä partir d'une donn√©e dont on a masqu√© automatiquement une partie de l'information, le mod√®le doit reconstruire la donn√©e compl√®te.
                    Pour les images, cela peut consister √† masquer al√©atoirement un groupe de pixels ; pour le texte, √† cacher certains mots.
                    
                </li>
                <li>
                    
                    <b>Les t√¢ches contrastives.</b> Le mod√®le est entra√Æn√© √† obtenir des repr√©sentations proches pour des images similaires (paires positives) et √©loign√©es pour des images diff√©rentes (paires n√©gatives).
                    Les paires positives sont obtenues en appliquant des transformations (ou augmentations de donn√©es) √† une m√™me image.
                    
                </li>
                <li>
                    
                    <b>Les t√¢ches d'invariance.</b> Le mod√®le apprend √† obtenir des repr√©sentations proches pour des images similaires.
                    Une solution triviale serait de consid√©rer toutes les images comme identiques ‚Äî un ph√©nom√®ne appel√© <i>effondrement</i>.
                    Pour √©viter cela, des contraintes de r√©gularisation sont appliqu√©es durant l'entra√Ænement.
                    
                </li>
            </ul>

            <h3>L'apprentissage auto-supervis√© appliqu√© aux donn√©es spectrales</h3>
            <p>
                
                Si l'apprentissage auto-supervis√© est tr√®s populaire pour les images et le texte, il est encore quasi inexistant pour les donn√©es spectrales.
                C'est pourquoi PellencST et l'√©quipe COMIC ont lanc√© une th√®se intitul√©e ¬´ Apprentissage auto-supervis√© appliqu√© aux donn√©es spectrales pour le tri des d√©chets ¬ª.
                Cette th√®se, r√©alis√©e par Ivy Tumoine, est co-dirig√©e par Ryad Bendoula et Jean-Michel Roger, et co-encadr√©e par Maxime Metz et Florent Abdelghafour.
                
            </p>

            <p>
                
                L'adaptation de ces approches auto-supervis√©es n√©cessite de lever trois verrous m√©thodologiques majeurs :
                
            </p>

            <ul>
                <li>
                    
                    <b>Augmentation de donn√©es spectrales.</b> Les approches auto-supervis√©es cherchent √† rendre les mod√®les invariants √† certaines perturbations via des augmentations de donn√©es.
                    Cependant, peu de recherches concernent les augmentations adapt√©es aux spectres.
                    Comme ces transformations influencent directement les connaissances apprises, elles doivent √™tre con√ßues en tenant compte de la nature des donn√©es spectrales : composition, d√©pendances lointaines, conditions de mesure, etc.
                    
                </li>
                <li>
                    
                    <b>R√©seaux neuronaux adapt√©s aux donn√©es spectrales.</b> Ces approches n√©cessiteront sans doute des architectures mieux adapt√©es aux spectres.
                    Si de nombreux r√©seaux existent pour les images et les vid√©os, peu sont optimis√©s pour les donn√©es spectrales.
                    Les ResNet, par exemple, ne prennent pas toujours en compte les corr√©lations lointaines entre longueurs d‚Äôonde.
                    De nouvelles architectures comme les Transformers (SWIN, ViT, etc.) devront √™tre explor√©es.
                    
                </li>
                <li>
                    
                    <b>Strat√©gies d'auto-supervision adapt√©es aux donn√©es spectrales.</b> Les strat√©gies utilis√©es dans d'autres domaines ne tiennent pas compte de la structure spectrale.
                    Par exemple, le masquage spatial classique n'est pas adapt√© car certaines signatures spectrales ne d√©pendent que d'une gamme de longueurs d'onde.
                    L'objectif sera donc de concevoir de nouvelles strat√©gies d'auto-supervision adapt√©es, par exemple en masquant une partie des structures latentes.
                    
                </li>
            </ul>
        </div>
    </div>
</div>

<a href="/fr/actualites/">Retour</a>


</div>

<footer>
    <p>&copy; 2025 Labcom AIOLY. Tous droits r√©serv√©s.</p>
</footer>

</body>
</html>
